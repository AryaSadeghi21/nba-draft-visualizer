{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f15392e3-ce8f-4b3a-9845-28d7e14a3ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryaarya/projects/nba-draft-visualizer/notebooks/.venv/lib/python3.13/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:18: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa: F401\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "804265ec-21e4-4eb6-9d3f-de3e26091df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"cleaned_datasets/training_data.csv\")\n",
    "all_data = pd.read_csv(\"cleaned_datasets/all_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "161b1f72-b31a-4977-bcac-6f2e105d5107",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"AGE\",\"GP\",\"MpG\",\"PpG\",\"RpG\",\"ApG\",\"SpG\",\"BpG\",\"TOpG\"]\n",
    "seasons = sorted(training_data[\"SEASON\"].unique())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "514fb376-07a0-478b-af82-39a507cdac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_series(y_true, y_pred):\n",
    "    return float(mean_absolute_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0122a4fa-7a0c-4872-9820-4df741b6880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive baseline per fold\n",
    "rows = []\n",
    "for t in seasons[:-1]:\n",
    "    test = training_data[training_data.SEASON == t+1].copy()\n",
    "    prev = training_data[training_data.SEASON == t][[\"NAME\",\"FP_total\"]].rename(columns={\"FP_total\":\"prev_FP\"})\n",
    "    test = test.merge(prev, on=\"NAME\", how=\"left\")\n",
    "    m = test[\"prev_FP\"].notna()\n",
    "    naive_mae = mae_series(test.loc[m,\"FP_total_next\"], test.loc[m,\"prev_FP\"])\n",
    "\n",
    "    # models trained on <= t, tested on t+1\n",
    "    train = training_data[training_data.SEASON <= t]\n",
    "    Xtr, ytr = train[features], train[\"FP_total_next\"]\n",
    "    Xte, yte = test[features], test[\"FP_total_next\"]\n",
    "\n",
    "    models = {\n",
    "        \"Linear\": LinearRegression(),\n",
    "        \"Ridge\": Ridge(alpha=1.0, random_state=42),\n",
    "        \"RF\": RandomForestRegressor(n_estimators=300, max_depth=None, random_state=42, n_jobs=-1),\n",
    "        \"HGB\": HistGradientBoostingRegressor(max_depth=None, learning_rate=0.05, max_iter=500, random_state=42),\n",
    "    }\n",
    "    maes = {}\n",
    "    for name, mdl in models.items():\n",
    "        mdl.fit(Xtr, ytr)\n",
    "        maes[name] = mae_series(yte, mdl.predict(Xte))\n",
    "\n",
    "    rows.append({\n",
    "        \"train_upto\": t,\n",
    "        \"test_year\": t+1,\n",
    "        \"Naive\": naive_mae,\n",
    "        **maes\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b7b7fb-da6b-495a-869d-55991c8f507b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'FP_total'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/nba-draft-visualizer/notebooks/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'FP_total'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m Xtr, ytr = train[features], train[\u001b[33m\"\u001b[39m\u001b[33mFP_total_next\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      5\u001b[39m test24 = all_data[all_data.SEASON == \u001b[32m2024\u001b[39m].copy()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m Xte, yte_24 = test24[features], \u001b[43mtest24\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFP_total\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/nba-draft-visualizer/notebooks/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/nba-draft-visualizer/notebooks/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'FP_total'"
     ]
    }
   ],
   "source": [
    "# add 2023->2024 fold explicitly (train on <=2023, test on 2024 actual FPpG)\n",
    "t = 2023\n",
    "train = training_data[training_data.SEASON <= t]\n",
    "Xtr, ytr = train[features], train[\"FP_total_next\"]\n",
    "test24 = all_data[all_data.SEASON == 2024].copy()\n",
    "Xte, yte_24 = test24[features], test24[\"FP_total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3e464-b9c0-42c6-9a46-1623ba027cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start clean and align indexes\n",
    "test24 = all_data[all_data.SEASON == 2024][[\"NAME\",\"FP_total_next\"] + features].copy().reset_index(drop=True)\n",
    "\n",
    "prev23 = training_data[training_data.SEASON == 2023][[\"NAME\",\"FP_total\"]].rename(columns={\"FP_total\":\"prev_FP\"})\n",
    "test24 = test24.merge(prev23, on=\"NAME\", how=\"left\")\n",
    "\n",
    "m = test24[\"prev_FP\"].notna()\n",
    "naive24 = mean_absolute_error(test24.loc[m, \"FP_total\"], test24.loc[m, \"prev_FP\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff6f34-4914-412a-bf1b-1442ac9e3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Linear\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0, random_state=42),\n",
    "    \"RF\": RandomForestRegressor(n_estimators=300, max_depth=None, random_state=42, n_jobs=-1),\n",
    "    \"HGB\": HistGradientBoostingRegressor(max_depth=None, learning_rate=0.05, max_iter=500, random_state=42),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9daad69-049f-4fcc-9b92-5be970f21f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "maes24 = {}\n",
    "for name, mdl in models.items():\n",
    "    mdl.fit(Xtr, ytr)\n",
    "    maes24[name] = mae_series(yte_24, mdl.predict(Xte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b31171-cfba-4994-a960-184b5f3ed019",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows.append({\n",
    "    \"train_upto\": 2023,\n",
    "    \"test_year\": 2024,\n",
    "    \"Naive\": naive24,\n",
    "    **maes24\n",
    "})\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "avg_row = {\"train_upto\":\"Avg\",\"test_year\":\"—\"}\n",
    "for col in [\"Naive\",\"Linear\",\"Ridge\",\"RF\",\"HGB\"]:\n",
    "    avg_row[col] = results_df[col].mean()\n",
    "results_df = pd.concat([results_df, pd.DataFrame([avg_row])], ignore_index=True)\n",
    "\n",
    "results_df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3585b62e-a91c-4718-9f1f-7384e16341fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from here, we learn that "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nba-env)",
   "language": "python",
   "name": "nba-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
